{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6743c-5393-4304-adc5-63a2f012f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb87442b-98b6-499d-83bc-e13d9254911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, GenerationConfig, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc8cf4-af62-4759-bc8d-91d95fc07fa3",
   "metadata": {},
   "source": [
    "#### json to csv (시험지 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979cf95-e80c-43b0-b6cd-178c39938a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_csv(json_file_path, csv_file_path):\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for item in data:\n",
    "\n",
    "        conversation = item[\"input\"][\"conversation\"]\n",
    "        category = item[\"input\"][\"subject_keyword\"]\n",
    "        output = \"\"\n",
    "\n",
    "        conversation_text = \"[Conversation]\\n\"\n",
    "        for utterance in conversation:\n",
    "            speaker = f\"화자{utterance['speaker']}\"\n",
    "            text = utterance[\"utterance\"]\n",
    "            conversation_text += f\"{speaker}: {text}\\n\"\n",
    "\n",
    "            category_text = \", \".join(category)\n",
    "\n",
    "            question_text = (\n",
    "                f\"\\n[Question]\\n위 {category_text} 주제에 대한 대화를 요약해주세요.\"\n",
    "            )\n",
    "\n",
    "        instruction_text = conversation_text + question_text\n",
    "\n",
    "        rows.append({\"instruction\": instruction_text, \"output\": output})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_file_path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9866407-cb32-4467-9832-4e272f909d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 데이터 파일 경로\n",
    "json_file_path = \"./data/일상대화요약_test.json\"\n",
    "# 결과를 저장할 CSV 파일 경로\n",
    "csv_file_path = \"./data/일상대화요약_시험지.csv\"\n",
    "\n",
    "convert_json_to_csv(json_file_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bebcaf-d4b8-4b57-b4c2-aa3c4a4df9bf",
   "metadata": {},
   "source": [
    "### 1. 일반 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd729e54-9ef2-414c-b037-f739e68227a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"cpm-ai/Gemma2-Malpyung-DailyConversationSummary-NA\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL,\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             device_map={\"\":0},\n",
    "                                            )\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f0c32-4c39-4e92-913a-59da8f65372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/일상대화요약_시험지.csv')\n",
    "output=[]\n",
    "for index, instruction in tqdm(df['instruction'].items()):\n",
    "    \n",
    "    print(f\"처리 중인 행: {index}\")\n",
    "    \n",
    "    text = instruction\n",
    "\n",
    "    chat = [\n",
    "    { \"role\": \"user\", \"content\": f\"\"\"{text}\"\"\" }\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=inputs.to(model.device), \n",
    "                             max_new_tokens=1024,\n",
    "                             do_sample=False,\n",
    "                             streamer=streamer\n",
    "                            )\n",
    "\n",
    "    input_length = inputs.shape[1]\n",
    "    model_output = outputs[0][input_length:]\n",
    "    decoded_output = tokenizer.decode(model_output, skip_special_tokens=True)\n",
    "    cleaned_text = decoded_output.rstrip('\\n')\n",
    "    \n",
    "    response = cleaned_text\n",
    "\n",
    "    print('output')\n",
    "    print(response)\n",
    "    \n",
    "    output.append(response)\n",
    "\n",
    "df['output'] = output\n",
    "\n",
    "# 답지 저장\n",
    "df.to_csv('./data/일상대화요약_답지.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7981d5-559f-4f99-b9a0-dd8cd2ea7e97",
   "metadata": {},
   "source": [
    "### 2. Vllm 추론 (더 빠른 추론 속도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684396e-6c72-4c1c-bc97-8e0c3af0a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1502b40a-f47d-42dd-90f6-a11b5e3b34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ['VLLM_ALLOW_LONG_MAX_MODEL_LEN'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e40060-0f36-4d46-92f9-5f719de59dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=\"cpm-ai/Gemma2-Malpyung-DailyConversationSummary-NA\", \n",
    "    max_model_len=4096,\n",
    "    # gpu_memory_utilization=0.3, # gpu 메모리 사용량\n",
    "    enforce_eager=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38496c-c7ef-488f-af84-6279bb68b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/일상대화요약_시험지.csv')\n",
    "sampling_params = SamplingParams(temperature=0, max_tokens=1024)\n",
    "output=[]\n",
    "\n",
    "for index, instruction in tqdm(df['instruction'].items()):\n",
    "\n",
    "    print(f\"처리 중인 행: {index}\")\n",
    "    \n",
    "    text = instruction\n",
    "    \n",
    "    formatted_prompt = f\"<bos><start_of_turn>user\\n{text}<end_of_turn>\\n<start_of_turn>model\\n'\"\n",
    "    \n",
    "    # 답변 생성\n",
    "    outputs = llm.generate(formatted_prompt, sampling_params)\n",
    "    print('outputs확인')\n",
    "    print(outputs[0].outputs[0].text)\n",
    "    \n",
    "    # 생성된 텍스트 추출\n",
    "    response = outputs[0].outputs[0].text.strip()\n",
    "\n",
    "    output.append(response)\n",
    "\n",
    "df['output'] = output\n",
    "\n",
    "# 답지 저장\n",
    "df.to_csv('./data/일상대화요약_답지.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0936f095-7601-4735-b7b8-c99ea8f82986",
   "metadata": {},
   "source": [
    "### 제출용 답지 생성 (csv to json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb67901-6a2e-4802-a050-131941f463a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712f9d5-f24b-4dd6-a4b6-3c5fa949ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답지 경로\n",
    "csv_file = './data/일상대화요약_답지.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# JSON 파일 읽기\n",
    "json_file = './data/일상대화요약_test.json'\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# CSV의 'output' 열 데이터를 JSON에 삽입\n",
    "for i, item in enumerate(json_data):\n",
    "    if i < len(df):\n",
    "        item['output'] = df.loc[i, 'output']\n",
    "\n",
    "# 수정된 JSON 데이터를 파일에 쓰기\n",
    "output_json_file = './data/result.json'  # 출력 JSON 파일 경로를 지정하세요\n",
    "with open(output_json_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"작업이 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malpyung_test",
   "language": "python",
   "name": "malpyung_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
